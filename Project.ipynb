{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-SdN7AO0h_P"
      },
      "source": [
        "##DESCRIPTION##\n",
        "\n",
        "**Context :**\n",
        "This database contains 76 attributes, but all published experiments refer to using a subset of 14 of them. In particular, the Cleveland database is the only one that has been used by ML researchers to\n",
        "this date. The \"goal\" field refers to the presence of heart disease in the patient. It is integer valued from 0 (no presence) to 4.\n",
        "\n",
        "\n",
        "**Attribute Information:**\n",
        "\n",
        "1. age\n",
        "\n",
        "2. sex\n",
        "\n",
        "3. chest pain type (4 values)\n",
        "\n",
        "4. resting blood pressure\n",
        "\n",
        "5. serum cholestoral in mg/dl\n",
        "\n",
        "6. fasting blood sugar > 120 mg/dl\n",
        "\n",
        "7. resting electrocardiographic results (values 0,1,2)\n",
        "\n",
        "8. maximum heart rate achieved\n",
        "9. exercise induced angina\n",
        "10. oldpeak = ST depression induced by exercise relative to rest\n",
        "11. the slope of the peak exercise ST segment\n",
        "12. number of major vessels (0-3) colored by flourosopy\n",
        "13. thal: 3 = normal; 6 = fixed defect; 7 = reversable defect\n",
        "14. target value(0 if no , if if yes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGh8DP6kxnfx"
      },
      "source": [
        "##IMPORTING LIBRARIES AND DATASET##\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8n6jJLiixuRy"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors\n",
        "from sklearn.metrics import accuracy_score , confusion_matrix\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from matplotlib.cm import rainbow\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
        "from sklearn.metrics import classification_report\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D55grtWtuA1H"
      },
      "source": [
        "mycmap = matplotlib.colors.LinearSegmentedColormap.from_list(\" \" ,[\"red\",\"yellow\",\"green\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UK4tL8O_uE6I"
      },
      "source": [
        "data = pd.read_csv(\"Training.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxky7oqOuU44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "38f7c7dd-f7a4-4332-d86b-be134b4a6ae4"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>itching</th>\n",
              "      <th>skin_rash</th>\n",
              "      <th>nodal_skin_eruptions</th>\n",
              "      <th>continuous_sneezing</th>\n",
              "      <th>shivering</th>\n",
              "      <th>chills</th>\n",
              "      <th>joint_pain</th>\n",
              "      <th>stomach_pain</th>\n",
              "      <th>acidity</th>\n",
              "      <th>ulcers_on_tongue</th>\n",
              "      <th>muscle_wasting</th>\n",
              "      <th>vomiting</th>\n",
              "      <th>burning_micturition</th>\n",
              "      <th>spotting_ urination</th>\n",
              "      <th>fatigue</th>\n",
              "      <th>weight_gain</th>\n",
              "      <th>anxiety</th>\n",
              "      <th>cold_hands_and_feets</th>\n",
              "      <th>mood_swings</th>\n",
              "      <th>weight_loss</th>\n",
              "      <th>restlessness</th>\n",
              "      <th>lethargy</th>\n",
              "      <th>patches_in_throat</th>\n",
              "      <th>irregular_sugar_level</th>\n",
              "      <th>cough</th>\n",
              "      <th>high_fever</th>\n",
              "      <th>sunken_eyes</th>\n",
              "      <th>breathlessness</th>\n",
              "      <th>sweating</th>\n",
              "      <th>dehydration</th>\n",
              "      <th>indigestion</th>\n",
              "      <th>headache</th>\n",
              "      <th>yellowish_skin</th>\n",
              "      <th>dark_urine</th>\n",
              "      <th>nausea</th>\n",
              "      <th>loss_of_appetite</th>\n",
              "      <th>pain_behind_the_eyes</th>\n",
              "      <th>back_pain</th>\n",
              "      <th>constipation</th>\n",
              "      <th>abdominal_pain</th>\n",
              "      <th>...</th>\n",
              "      <th>internal_itching</th>\n",
              "      <th>toxic_look_(typhos)</th>\n",
              "      <th>depression</th>\n",
              "      <th>irritability</th>\n",
              "      <th>muscle_pain</th>\n",
              "      <th>altered_sensorium</th>\n",
              "      <th>red_spots_over_body</th>\n",
              "      <th>belly_pain</th>\n",
              "      <th>abnormal_menstruation</th>\n",
              "      <th>dischromic _patches</th>\n",
              "      <th>watering_from_eyes</th>\n",
              "      <th>increased_appetite</th>\n",
              "      <th>polyuria</th>\n",
              "      <th>family_history</th>\n",
              "      <th>mucoid_sputum</th>\n",
              "      <th>rusty_sputum</th>\n",
              "      <th>lack_of_concentration</th>\n",
              "      <th>visual_disturbances</th>\n",
              "      <th>receiving_blood_transfusion</th>\n",
              "      <th>receiving_unsterile_injections</th>\n",
              "      <th>coma</th>\n",
              "      <th>stomach_bleeding</th>\n",
              "      <th>distention_of_abdomen</th>\n",
              "      <th>history_of_alcohol_consumption</th>\n",
              "      <th>fluid_overload.1</th>\n",
              "      <th>blood_in_sputum</th>\n",
              "      <th>prominent_veins_on_calf</th>\n",
              "      <th>palpitations</th>\n",
              "      <th>painful_walking</th>\n",
              "      <th>pus_filled_pimples</th>\n",
              "      <th>blackheads</th>\n",
              "      <th>scurring</th>\n",
              "      <th>skin_peeling</th>\n",
              "      <th>silver_like_dusting</th>\n",
              "      <th>small_dents_in_nails</th>\n",
              "      <th>inflammatory_nails</th>\n",
              "      <th>blister</th>\n",
              "      <th>red_sore_around_nose</th>\n",
              "      <th>yellow_crust_ooze</th>\n",
              "      <th>prognosis</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Fungal infection</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Fungal infection</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Fungal infection</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Fungal infection</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Fungal infection</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 133 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   itching  skin_rash  ...  yellow_crust_ooze         prognosis\n",
              "0        1          1  ...                  0  Fungal infection\n",
              "1        0          1  ...                  0  Fungal infection\n",
              "2        1          0  ...                  0  Fungal infection\n",
              "3        1          1  ...                  0  Fungal infection\n",
              "4        1          1  ...                  0  Fungal infection\n",
              "\n",
              "[5 rows x 133 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFAG8mjeQyby",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "582f8b3d-c56b-4d1d-81e0-cf964aeba3cc"
      },
      "source": [
        "data.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>itching</th>\n",
              "      <th>skin_rash</th>\n",
              "      <th>nodal_skin_eruptions</th>\n",
              "      <th>continuous_sneezing</th>\n",
              "      <th>shivering</th>\n",
              "      <th>chills</th>\n",
              "      <th>joint_pain</th>\n",
              "      <th>stomach_pain</th>\n",
              "      <th>acidity</th>\n",
              "      <th>ulcers_on_tongue</th>\n",
              "      <th>muscle_wasting</th>\n",
              "      <th>vomiting</th>\n",
              "      <th>burning_micturition</th>\n",
              "      <th>spotting_ urination</th>\n",
              "      <th>fatigue</th>\n",
              "      <th>weight_gain</th>\n",
              "      <th>anxiety</th>\n",
              "      <th>cold_hands_and_feets</th>\n",
              "      <th>mood_swings</th>\n",
              "      <th>weight_loss</th>\n",
              "      <th>restlessness</th>\n",
              "      <th>lethargy</th>\n",
              "      <th>patches_in_throat</th>\n",
              "      <th>irregular_sugar_level</th>\n",
              "      <th>cough</th>\n",
              "      <th>high_fever</th>\n",
              "      <th>sunken_eyes</th>\n",
              "      <th>breathlessness</th>\n",
              "      <th>sweating</th>\n",
              "      <th>dehydration</th>\n",
              "      <th>indigestion</th>\n",
              "      <th>headache</th>\n",
              "      <th>yellowish_skin</th>\n",
              "      <th>dark_urine</th>\n",
              "      <th>nausea</th>\n",
              "      <th>loss_of_appetite</th>\n",
              "      <th>pain_behind_the_eyes</th>\n",
              "      <th>back_pain</th>\n",
              "      <th>constipation</th>\n",
              "      <th>abdominal_pain</th>\n",
              "      <th>...</th>\n",
              "      <th>passage_of_gases</th>\n",
              "      <th>internal_itching</th>\n",
              "      <th>toxic_look_(typhos)</th>\n",
              "      <th>depression</th>\n",
              "      <th>irritability</th>\n",
              "      <th>muscle_pain</th>\n",
              "      <th>altered_sensorium</th>\n",
              "      <th>red_spots_over_body</th>\n",
              "      <th>belly_pain</th>\n",
              "      <th>abnormal_menstruation</th>\n",
              "      <th>dischromic _patches</th>\n",
              "      <th>watering_from_eyes</th>\n",
              "      <th>increased_appetite</th>\n",
              "      <th>polyuria</th>\n",
              "      <th>family_history</th>\n",
              "      <th>mucoid_sputum</th>\n",
              "      <th>rusty_sputum</th>\n",
              "      <th>lack_of_concentration</th>\n",
              "      <th>visual_disturbances</th>\n",
              "      <th>receiving_blood_transfusion</th>\n",
              "      <th>receiving_unsterile_injections</th>\n",
              "      <th>coma</th>\n",
              "      <th>stomach_bleeding</th>\n",
              "      <th>distention_of_abdomen</th>\n",
              "      <th>history_of_alcohol_consumption</th>\n",
              "      <th>fluid_overload.1</th>\n",
              "      <th>blood_in_sputum</th>\n",
              "      <th>prominent_veins_on_calf</th>\n",
              "      <th>palpitations</th>\n",
              "      <th>painful_walking</th>\n",
              "      <th>pus_filled_pimples</th>\n",
              "      <th>blackheads</th>\n",
              "      <th>scurring</th>\n",
              "      <th>skin_peeling</th>\n",
              "      <th>silver_like_dusting</th>\n",
              "      <th>small_dents_in_nails</th>\n",
              "      <th>inflammatory_nails</th>\n",
              "      <th>blister</th>\n",
              "      <th>red_sore_around_nose</th>\n",
              "      <th>yellow_crust_ooze</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "      <td>4920.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.137805</td>\n",
              "      <td>0.159756</td>\n",
              "      <td>0.021951</td>\n",
              "      <td>0.045122</td>\n",
              "      <td>0.021951</td>\n",
              "      <td>0.162195</td>\n",
              "      <td>0.139024</td>\n",
              "      <td>0.045122</td>\n",
              "      <td>0.045122</td>\n",
              "      <td>0.021951</td>\n",
              "      <td>0.021951</td>\n",
              "      <td>0.389024</td>\n",
              "      <td>0.043902</td>\n",
              "      <td>0.021951</td>\n",
              "      <td>0.392683</td>\n",
              "      <td>0.023171</td>\n",
              "      <td>0.023171</td>\n",
              "      <td>0.023171</td>\n",
              "      <td>0.046341</td>\n",
              "      <td>0.092683</td>\n",
              "      <td>0.046341</td>\n",
              "      <td>0.092683</td>\n",
              "      <td>0.021951</td>\n",
              "      <td>0.023171</td>\n",
              "      <td>0.114634</td>\n",
              "      <td>0.276829</td>\n",
              "      <td>0.021951</td>\n",
              "      <td>0.091463</td>\n",
              "      <td>0.137805</td>\n",
              "      <td>0.021951</td>\n",
              "      <td>0.045122</td>\n",
              "      <td>0.230488</td>\n",
              "      <td>0.185366</td>\n",
              "      <td>0.115854</td>\n",
              "      <td>0.232927</td>\n",
              "      <td>0.234146</td>\n",
              "      <td>0.024390</td>\n",
              "      <td>0.046341</td>\n",
              "      <td>0.046341</td>\n",
              "      <td>0.209756</td>\n",
              "      <td>...</td>\n",
              "      <td>0.023171</td>\n",
              "      <td>0.023171</td>\n",
              "      <td>0.023171</td>\n",
              "      <td>0.047561</td>\n",
              "      <td>0.096341</td>\n",
              "      <td>0.096341</td>\n",
              "      <td>0.023171</td>\n",
              "      <td>0.047561</td>\n",
              "      <td>0.023171</td>\n",
              "      <td>0.048780</td>\n",
              "      <td>0.021951</td>\n",
              "      <td>0.021951</td>\n",
              "      <td>0.024390</td>\n",
              "      <td>0.024390</td>\n",
              "      <td>0.046341</td>\n",
              "      <td>0.023171</td>\n",
              "      <td>0.024390</td>\n",
              "      <td>0.023171</td>\n",
              "      <td>0.023171</td>\n",
              "      <td>0.024390</td>\n",
              "      <td>0.024390</td>\n",
              "      <td>0.024390</td>\n",
              "      <td>0.024390</td>\n",
              "      <td>0.023171</td>\n",
              "      <td>0.023171</td>\n",
              "      <td>0.023171</td>\n",
              "      <td>0.024390</td>\n",
              "      <td>0.023171</td>\n",
              "      <td>0.024390</td>\n",
              "      <td>0.046341</td>\n",
              "      <td>0.021951</td>\n",
              "      <td>0.021951</td>\n",
              "      <td>0.021951</td>\n",
              "      <td>0.023171</td>\n",
              "      <td>0.023171</td>\n",
              "      <td>0.023171</td>\n",
              "      <td>0.023171</td>\n",
              "      <td>0.023171</td>\n",
              "      <td>0.023171</td>\n",
              "      <td>0.023171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.344730</td>\n",
              "      <td>0.366417</td>\n",
              "      <td>0.146539</td>\n",
              "      <td>0.207593</td>\n",
              "      <td>0.146539</td>\n",
              "      <td>0.368667</td>\n",
              "      <td>0.346007</td>\n",
              "      <td>0.207593</td>\n",
              "      <td>0.207593</td>\n",
              "      <td>0.146539</td>\n",
              "      <td>0.146539</td>\n",
              "      <td>0.487578</td>\n",
              "      <td>0.204899</td>\n",
              "      <td>0.146539</td>\n",
              "      <td>0.488397</td>\n",
              "      <td>0.150461</td>\n",
              "      <td>0.150461</td>\n",
              "      <td>0.150461</td>\n",
              "      <td>0.210245</td>\n",
              "      <td>0.290017</td>\n",
              "      <td>0.210245</td>\n",
              "      <td>0.290017</td>\n",
              "      <td>0.146539</td>\n",
              "      <td>0.150461</td>\n",
              "      <td>0.318612</td>\n",
              "      <td>0.447477</td>\n",
              "      <td>0.146539</td>\n",
              "      <td>0.288296</td>\n",
              "      <td>0.344730</td>\n",
              "      <td>0.146539</td>\n",
              "      <td>0.207593</td>\n",
              "      <td>0.421188</td>\n",
              "      <td>0.388634</td>\n",
              "      <td>0.320082</td>\n",
              "      <td>0.422739</td>\n",
              "      <td>0.423507</td>\n",
              "      <td>0.154273</td>\n",
              "      <td>0.210245</td>\n",
              "      <td>0.210245</td>\n",
              "      <td>0.407176</td>\n",
              "      <td>...</td>\n",
              "      <td>0.150461</td>\n",
              "      <td>0.150461</td>\n",
              "      <td>0.150461</td>\n",
              "      <td>0.212857</td>\n",
              "      <td>0.295089</td>\n",
              "      <td>0.295089</td>\n",
              "      <td>0.150461</td>\n",
              "      <td>0.212857</td>\n",
              "      <td>0.150461</td>\n",
              "      <td>0.215431</td>\n",
              "      <td>0.146539</td>\n",
              "      <td>0.146539</td>\n",
              "      <td>0.154273</td>\n",
              "      <td>0.154273</td>\n",
              "      <td>0.210245</td>\n",
              "      <td>0.150461</td>\n",
              "      <td>0.154273</td>\n",
              "      <td>0.150461</td>\n",
              "      <td>0.150461</td>\n",
              "      <td>0.154273</td>\n",
              "      <td>0.154273</td>\n",
              "      <td>0.154273</td>\n",
              "      <td>0.154273</td>\n",
              "      <td>0.150461</td>\n",
              "      <td>0.150461</td>\n",
              "      <td>0.150461</td>\n",
              "      <td>0.154273</td>\n",
              "      <td>0.150461</td>\n",
              "      <td>0.154273</td>\n",
              "      <td>0.210245</td>\n",
              "      <td>0.146539</td>\n",
              "      <td>0.146539</td>\n",
              "      <td>0.146539</td>\n",
              "      <td>0.150461</td>\n",
              "      <td>0.150461</td>\n",
              "      <td>0.150461</td>\n",
              "      <td>0.150461</td>\n",
              "      <td>0.150461</td>\n",
              "      <td>0.150461</td>\n",
              "      <td>0.150461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 132 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           itching    skin_rash  ...  red_sore_around_nose  yellow_crust_ooze\n",
              "count  4920.000000  4920.000000  ...           4920.000000        4920.000000\n",
              "mean      0.137805     0.159756  ...              0.023171           0.023171\n",
              "std       0.344730     0.366417  ...              0.150461           0.150461\n",
              "min       0.000000     0.000000  ...              0.000000           0.000000\n",
              "25%       0.000000     0.000000  ...              0.000000           0.000000\n",
              "50%       0.000000     0.000000  ...              0.000000           0.000000\n",
              "75%       0.000000     0.000000  ...              0.000000           0.000000\n",
              "max       1.000000     1.000000  ...              1.000000           1.000000\n",
              "\n",
              "[8 rows x 132 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqGMGUW1usg3"
      },
      "source": [
        "##Skewness and Kurtosis:##\n",
        "**Skewness  :**\n",
        "\n",
        "Skewness refers to distortion or asymmetry in a symmetrical bell curve, or normal distribution, in a set of data. If the curve is shifted to the left or to the right, it is said to be skewed.\n",
        "\n",
        "**Kurtosis :**\n",
        "\n",
        "Kurtosis is a statistical measure that defines how heavily the tails of a distribution differ from the tails of a normal distribution. In other words, kurtosis identifies whether the tails of a given distribution contain extreme values.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8x0t3BF3weAI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ddc2379-9f4c-4126-8470-234f0fce78fd"
      },
      "source": [
        "print(\"Skewness:  \\n\" , data.skew())\n",
        "print(\"Kurtosis: \\n \" ,data.kurtosis())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Skewness:  \n",
            " itching                 2.102180\n",
            "skin_rash               1.857896\n",
            "nodal_skin_eruptions    6.527172\n",
            "continuous_sneezing     4.384192\n",
            "shivering               6.527172\n",
            "                          ...   \n",
            "small_dents_in_nails    6.340830\n",
            "inflammatory_nails      6.340830\n",
            "blister                 6.340830\n",
            "red_sore_around_nose    6.340830\n",
            "yellow_crust_ooze       6.340830\n",
            "Length: 132, dtype: float64\n",
            "Kurtosis: \n",
            "  itching                  2.420145\n",
            "skin_rash                1.452367\n",
            "nodal_skin_eruptions    40.620488\n",
            "continuous_sneezing     17.228139\n",
            "shivering               40.620488\n",
            "                          ...    \n",
            "small_dents_in_nails    38.221666\n",
            "inflammatory_nails      38.221666\n",
            "blister                 38.221666\n",
            "red_sore_around_nose    38.221666\n",
            "yellow_crust_ooze       38.221666\n",
            "Length: 132, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8mT_je0x_xH"
      },
      "source": [
        "##CORRELATION MATRIX : ##\n",
        "A correlation matrix is a table showing correlation coefficients between variables. Each cell in the table shows the correlation between two variables. A correlation matrix is used to summarize data, as an input into a more advanced analysis, and as a diagnostic for advanced analyses."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZS07jbOmx1_O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "outputId": "07c63eac-2540-4498-86c3-f4b44f546a0c"
      },
      "source": [
        "data.corr('pearson')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>itching</th>\n",
              "      <th>skin_rash</th>\n",
              "      <th>nodal_skin_eruptions</th>\n",
              "      <th>continuous_sneezing</th>\n",
              "      <th>shivering</th>\n",
              "      <th>chills</th>\n",
              "      <th>joint_pain</th>\n",
              "      <th>stomach_pain</th>\n",
              "      <th>acidity</th>\n",
              "      <th>ulcers_on_tongue</th>\n",
              "      <th>muscle_wasting</th>\n",
              "      <th>vomiting</th>\n",
              "      <th>burning_micturition</th>\n",
              "      <th>spotting_ urination</th>\n",
              "      <th>fatigue</th>\n",
              "      <th>weight_gain</th>\n",
              "      <th>anxiety</th>\n",
              "      <th>cold_hands_and_feets</th>\n",
              "      <th>mood_swings</th>\n",
              "      <th>weight_loss</th>\n",
              "      <th>restlessness</th>\n",
              "      <th>lethargy</th>\n",
              "      <th>patches_in_throat</th>\n",
              "      <th>irregular_sugar_level</th>\n",
              "      <th>cough</th>\n",
              "      <th>high_fever</th>\n",
              "      <th>sunken_eyes</th>\n",
              "      <th>breathlessness</th>\n",
              "      <th>sweating</th>\n",
              "      <th>dehydration</th>\n",
              "      <th>indigestion</th>\n",
              "      <th>headache</th>\n",
              "      <th>yellowish_skin</th>\n",
              "      <th>dark_urine</th>\n",
              "      <th>nausea</th>\n",
              "      <th>loss_of_appetite</th>\n",
              "      <th>pain_behind_the_eyes</th>\n",
              "      <th>back_pain</th>\n",
              "      <th>constipation</th>\n",
              "      <th>abdominal_pain</th>\n",
              "      <th>...</th>\n",
              "      <th>passage_of_gases</th>\n",
              "      <th>internal_itching</th>\n",
              "      <th>toxic_look_(typhos)</th>\n",
              "      <th>depression</th>\n",
              "      <th>irritability</th>\n",
              "      <th>muscle_pain</th>\n",
              "      <th>altered_sensorium</th>\n",
              "      <th>red_spots_over_body</th>\n",
              "      <th>belly_pain</th>\n",
              "      <th>abnormal_menstruation</th>\n",
              "      <th>dischromic _patches</th>\n",
              "      <th>watering_from_eyes</th>\n",
              "      <th>increased_appetite</th>\n",
              "      <th>polyuria</th>\n",
              "      <th>family_history</th>\n",
              "      <th>mucoid_sputum</th>\n",
              "      <th>rusty_sputum</th>\n",
              "      <th>lack_of_concentration</th>\n",
              "      <th>visual_disturbances</th>\n",
              "      <th>receiving_blood_transfusion</th>\n",
              "      <th>receiving_unsterile_injections</th>\n",
              "      <th>coma</th>\n",
              "      <th>stomach_bleeding</th>\n",
              "      <th>distention_of_abdomen</th>\n",
              "      <th>history_of_alcohol_consumption</th>\n",
              "      <th>fluid_overload.1</th>\n",
              "      <th>blood_in_sputum</th>\n",
              "      <th>prominent_veins_on_calf</th>\n",
              "      <th>palpitations</th>\n",
              "      <th>painful_walking</th>\n",
              "      <th>pus_filled_pimples</th>\n",
              "      <th>blackheads</th>\n",
              "      <th>scurring</th>\n",
              "      <th>skin_peeling</th>\n",
              "      <th>silver_like_dusting</th>\n",
              "      <th>small_dents_in_nails</th>\n",
              "      <th>inflammatory_nails</th>\n",
              "      <th>blister</th>\n",
              "      <th>red_sore_around_nose</th>\n",
              "      <th>yellow_crust_ooze</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>itching</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.318158</td>\n",
              "      <td>0.326439</td>\n",
              "      <td>-0.086906</td>\n",
              "      <td>-0.059893</td>\n",
              "      <td>-0.175905</td>\n",
              "      <td>-0.160650</td>\n",
              "      <td>0.202850</td>\n",
              "      <td>-0.086906</td>\n",
              "      <td>-0.059893</td>\n",
              "      <td>-0.059893</td>\n",
              "      <td>-0.057763</td>\n",
              "      <td>0.207896</td>\n",
              "      <td>0.350585</td>\n",
              "      <td>0.069744</td>\n",
              "      <td>-0.061573</td>\n",
              "      <td>-0.061573</td>\n",
              "      <td>-0.061573</td>\n",
              "      <td>-0.088129</td>\n",
              "      <td>0.091830</td>\n",
              "      <td>-0.088129</td>\n",
              "      <td>0.311436</td>\n",
              "      <td>-0.059893</td>\n",
              "      <td>-0.061573</td>\n",
              "      <td>-0.143855</td>\n",
              "      <td>0.037309</td>\n",
              "      <td>-0.059893</td>\n",
              "      <td>-0.126848</td>\n",
              "      <td>-0.159830</td>\n",
              "      <td>-0.059893</td>\n",
              "      <td>-0.086906</td>\n",
              "      <td>-0.067585</td>\n",
              "      <td>0.300936</td>\n",
              "      <td>0.253240</td>\n",
              "      <td>-0.069644</td>\n",
              "      <td>0.230103</td>\n",
              "      <td>-0.063212</td>\n",
              "      <td>-0.088129</td>\n",
              "      <td>-0.088129</td>\n",
              "      <td>0.263282</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.061573</td>\n",
              "      <td>-0.061573</td>\n",
              "      <td>-0.061573</td>\n",
              "      <td>-0.089338</td>\n",
              "      <td>-0.130537</td>\n",
              "      <td>-0.130537</td>\n",
              "      <td>-0.061573</td>\n",
              "      <td>0.226497</td>\n",
              "      <td>-0.061573</td>\n",
              "      <td>-0.090534</td>\n",
              "      <td>0.326439</td>\n",
              "      <td>-0.059893</td>\n",
              "      <td>-0.063212</td>\n",
              "      <td>-0.063212</td>\n",
              "      <td>-0.088129</td>\n",
              "      <td>-0.061573</td>\n",
              "      <td>-0.063212</td>\n",
              "      <td>-0.061573</td>\n",
              "      <td>-0.061573</td>\n",
              "      <td>0.372559</td>\n",
              "      <td>0.372559</td>\n",
              "      <td>-0.063212</td>\n",
              "      <td>-0.063212</td>\n",
              "      <td>-0.061573</td>\n",
              "      <td>-0.061573</td>\n",
              "      <td>-0.061573</td>\n",
              "      <td>-0.063212</td>\n",
              "      <td>-0.061573</td>\n",
              "      <td>-0.063212</td>\n",
              "      <td>-0.088129</td>\n",
              "      <td>-0.059893</td>\n",
              "      <td>-0.059893</td>\n",
              "      <td>-0.059893</td>\n",
              "      <td>-0.061573</td>\n",
              "      <td>-0.061573</td>\n",
              "      <td>-0.061573</td>\n",
              "      <td>-0.061573</td>\n",
              "      <td>-0.061573</td>\n",
              "      <td>-0.061573</td>\n",
              "      <td>-0.061573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>skin_rash</th>\n",
              "      <td>0.318158</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.298143</td>\n",
              "      <td>-0.094786</td>\n",
              "      <td>-0.065324</td>\n",
              "      <td>-0.029324</td>\n",
              "      <td>0.171134</td>\n",
              "      <td>0.161784</td>\n",
              "      <td>-0.094786</td>\n",
              "      <td>-0.065324</td>\n",
              "      <td>-0.065324</td>\n",
              "      <td>-0.225046</td>\n",
              "      <td>0.166507</td>\n",
              "      <td>0.298143</td>\n",
              "      <td>-0.105248</td>\n",
              "      <td>-0.067156</td>\n",
              "      <td>-0.067156</td>\n",
              "      <td>-0.067156</td>\n",
              "      <td>-0.096120</td>\n",
              "      <td>-0.139363</td>\n",
              "      <td>-0.096120</td>\n",
              "      <td>0.067246</td>\n",
              "      <td>-0.065324</td>\n",
              "      <td>-0.067156</td>\n",
              "      <td>-0.156900</td>\n",
              "      <td>0.117059</td>\n",
              "      <td>-0.065324</td>\n",
              "      <td>-0.138350</td>\n",
              "      <td>-0.174323</td>\n",
              "      <td>-0.065324</td>\n",
              "      <td>-0.094786</td>\n",
              "      <td>0.053792</td>\n",
              "      <td>-0.207998</td>\n",
              "      <td>-0.157841</td>\n",
              "      <td>-0.090663</td>\n",
              "      <td>0.049731</td>\n",
              "      <td>0.341036</td>\n",
              "      <td>0.204714</td>\n",
              "      <td>-0.096120</td>\n",
              "      <td>-0.224648</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.067156</td>\n",
              "      <td>-0.067156</td>\n",
              "      <td>-0.067156</td>\n",
              "      <td>-0.097439</td>\n",
              "      <td>-0.142374</td>\n",
              "      <td>0.060683</td>\n",
              "      <td>-0.067156</td>\n",
              "      <td>0.481206</td>\n",
              "      <td>-0.067156</td>\n",
              "      <td>-0.098744</td>\n",
              "      <td>0.298143</td>\n",
              "      <td>-0.065324</td>\n",
              "      <td>-0.068944</td>\n",
              "      <td>-0.068944</td>\n",
              "      <td>-0.096120</td>\n",
              "      <td>-0.067156</td>\n",
              "      <td>-0.068944</td>\n",
              "      <td>-0.067156</td>\n",
              "      <td>-0.067156</td>\n",
              "      <td>-0.068944</td>\n",
              "      <td>-0.068944</td>\n",
              "      <td>-0.068944</td>\n",
              "      <td>-0.068944</td>\n",
              "      <td>-0.067156</td>\n",
              "      <td>-0.067156</td>\n",
              "      <td>-0.067156</td>\n",
              "      <td>-0.068944</td>\n",
              "      <td>-0.067156</td>\n",
              "      <td>-0.068944</td>\n",
              "      <td>-0.096120</td>\n",
              "      <td>0.320859</td>\n",
              "      <td>0.320859</td>\n",
              "      <td>0.320859</td>\n",
              "      <td>0.331087</td>\n",
              "      <td>0.331087</td>\n",
              "      <td>0.331087</td>\n",
              "      <td>0.331087</td>\n",
              "      <td>0.331087</td>\n",
              "      <td>0.331087</td>\n",
              "      <td>0.331087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nodal_skin_eruptions</th>\n",
              "      <td>0.326439</td>\n",
              "      <td>0.298143</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.032566</td>\n",
              "      <td>-0.022444</td>\n",
              "      <td>-0.065917</td>\n",
              "      <td>-0.060200</td>\n",
              "      <td>-0.032566</td>\n",
              "      <td>-0.032566</td>\n",
              "      <td>-0.022444</td>\n",
              "      <td>-0.022444</td>\n",
              "      <td>-0.119543</td>\n",
              "      <td>-0.032103</td>\n",
              "      <td>-0.022444</td>\n",
              "      <td>-0.120465</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.033025</td>\n",
              "      <td>-0.047882</td>\n",
              "      <td>-0.033025</td>\n",
              "      <td>-0.047882</td>\n",
              "      <td>-0.022444</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.053907</td>\n",
              "      <td>-0.092690</td>\n",
              "      <td>-0.022444</td>\n",
              "      <td>-0.047534</td>\n",
              "      <td>-0.059893</td>\n",
              "      <td>-0.022444</td>\n",
              "      <td>-0.032566</td>\n",
              "      <td>-0.081991</td>\n",
              "      <td>-0.071463</td>\n",
              "      <td>-0.054230</td>\n",
              "      <td>-0.082554</td>\n",
              "      <td>-0.082836</td>\n",
              "      <td>-0.023687</td>\n",
              "      <td>-0.033025</td>\n",
              "      <td>-0.033025</td>\n",
              "      <td>-0.077184</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.033478</td>\n",
              "      <td>-0.048916</td>\n",
              "      <td>-0.048916</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.033478</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.033926</td>\n",
              "      <td>0.886395</td>\n",
              "      <td>-0.022444</td>\n",
              "      <td>-0.023687</td>\n",
              "      <td>-0.023687</td>\n",
              "      <td>-0.033025</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.023687</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.023687</td>\n",
              "      <td>-0.023687</td>\n",
              "      <td>-0.023687</td>\n",
              "      <td>-0.023687</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.023687</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.023687</td>\n",
              "      <td>-0.033025</td>\n",
              "      <td>-0.022444</td>\n",
              "      <td>-0.022444</td>\n",
              "      <td>-0.022444</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.023073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>continuous_sneezing</th>\n",
              "      <td>-0.086906</td>\n",
              "      <td>-0.094786</td>\n",
              "      <td>-0.032566</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.608981</td>\n",
              "      <td>0.446238</td>\n",
              "      <td>-0.087351</td>\n",
              "      <td>-0.047254</td>\n",
              "      <td>-0.047254</td>\n",
              "      <td>-0.032566</td>\n",
              "      <td>-0.032566</td>\n",
              "      <td>-0.173459</td>\n",
              "      <td>-0.046581</td>\n",
              "      <td>-0.032566</td>\n",
              "      <td>0.041755</td>\n",
              "      <td>-0.033480</td>\n",
              "      <td>-0.033480</td>\n",
              "      <td>-0.033480</td>\n",
              "      <td>-0.047919</td>\n",
              "      <td>-0.069477</td>\n",
              "      <td>-0.047919</td>\n",
              "      <td>-0.069477</td>\n",
              "      <td>-0.032566</td>\n",
              "      <td>-0.033480</td>\n",
              "      <td>0.253730</td>\n",
              "      <td>0.101860</td>\n",
              "      <td>-0.032566</td>\n",
              "      <td>-0.068972</td>\n",
              "      <td>-0.086906</td>\n",
              "      <td>-0.032566</td>\n",
              "      <td>-0.047254</td>\n",
              "      <td>0.132137</td>\n",
              "      <td>-0.103694</td>\n",
              "      <td>-0.078689</td>\n",
              "      <td>-0.119787</td>\n",
              "      <td>-0.120196</td>\n",
              "      <td>-0.034371</td>\n",
              "      <td>-0.047919</td>\n",
              "      <td>-0.047919</td>\n",
              "      <td>-0.111995</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.033480</td>\n",
              "      <td>-0.033480</td>\n",
              "      <td>-0.033480</td>\n",
              "      <td>-0.048577</td>\n",
              "      <td>-0.070978</td>\n",
              "      <td>0.307345</td>\n",
              "      <td>-0.033480</td>\n",
              "      <td>-0.048577</td>\n",
              "      <td>-0.033480</td>\n",
              "      <td>-0.049227</td>\n",
              "      <td>-0.032566</td>\n",
              "      <td>0.608981</td>\n",
              "      <td>-0.034371</td>\n",
              "      <td>-0.034371</td>\n",
              "      <td>-0.047919</td>\n",
              "      <td>-0.033480</td>\n",
              "      <td>-0.034371</td>\n",
              "      <td>-0.033480</td>\n",
              "      <td>-0.033480</td>\n",
              "      <td>-0.034371</td>\n",
              "      <td>-0.034371</td>\n",
              "      <td>-0.034371</td>\n",
              "      <td>-0.034371</td>\n",
              "      <td>-0.033480</td>\n",
              "      <td>-0.033480</td>\n",
              "      <td>-0.033480</td>\n",
              "      <td>-0.034371</td>\n",
              "      <td>-0.033480</td>\n",
              "      <td>-0.034371</td>\n",
              "      <td>-0.047919</td>\n",
              "      <td>-0.032566</td>\n",
              "      <td>-0.032566</td>\n",
              "      <td>-0.032566</td>\n",
              "      <td>-0.033480</td>\n",
              "      <td>-0.033480</td>\n",
              "      <td>-0.033480</td>\n",
              "      <td>-0.033480</td>\n",
              "      <td>-0.033480</td>\n",
              "      <td>-0.033480</td>\n",
              "      <td>-0.033480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>shivering</th>\n",
              "      <td>-0.059893</td>\n",
              "      <td>-0.065324</td>\n",
              "      <td>-0.022444</td>\n",
              "      <td>0.608981</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.295332</td>\n",
              "      <td>-0.060200</td>\n",
              "      <td>-0.032566</td>\n",
              "      <td>-0.032566</td>\n",
              "      <td>-0.022444</td>\n",
              "      <td>-0.022444</td>\n",
              "      <td>-0.119543</td>\n",
              "      <td>-0.032103</td>\n",
              "      <td>-0.022444</td>\n",
              "      <td>-0.120465</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.033025</td>\n",
              "      <td>-0.047882</td>\n",
              "      <td>-0.033025</td>\n",
              "      <td>-0.047882</td>\n",
              "      <td>-0.022444</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.053907</td>\n",
              "      <td>-0.092690</td>\n",
              "      <td>-0.022444</td>\n",
              "      <td>-0.047534</td>\n",
              "      <td>-0.059893</td>\n",
              "      <td>-0.022444</td>\n",
              "      <td>-0.032566</td>\n",
              "      <td>-0.081991</td>\n",
              "      <td>-0.071463</td>\n",
              "      <td>-0.054230</td>\n",
              "      <td>-0.082554</td>\n",
              "      <td>-0.082836</td>\n",
              "      <td>-0.023687</td>\n",
              "      <td>-0.033025</td>\n",
              "      <td>-0.033025</td>\n",
              "      <td>-0.077184</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.033478</td>\n",
              "      <td>-0.048916</td>\n",
              "      <td>-0.048916</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.033478</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.033926</td>\n",
              "      <td>-0.022444</td>\n",
              "      <td>0.886395</td>\n",
              "      <td>-0.023687</td>\n",
              "      <td>-0.023687</td>\n",
              "      <td>-0.033025</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.023687</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.023687</td>\n",
              "      <td>-0.023687</td>\n",
              "      <td>-0.023687</td>\n",
              "      <td>-0.023687</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.023687</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.023687</td>\n",
              "      <td>-0.033025</td>\n",
              "      <td>-0.022444</td>\n",
              "      <td>-0.022444</td>\n",
              "      <td>-0.022444</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.023073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>small_dents_in_nails</th>\n",
              "      <td>-0.061573</td>\n",
              "      <td>0.331087</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.033480</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.067765</td>\n",
              "      <td>0.359845</td>\n",
              "      <td>-0.033480</td>\n",
              "      <td>-0.033480</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.122896</td>\n",
              "      <td>-0.033003</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.123844</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.033951</td>\n",
              "      <td>-0.049224</td>\n",
              "      <td>-0.033951</td>\n",
              "      <td>-0.049224</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.055419</td>\n",
              "      <td>-0.095290</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.048867</td>\n",
              "      <td>-0.061573</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.033480</td>\n",
              "      <td>-0.084290</td>\n",
              "      <td>-0.073467</td>\n",
              "      <td>-0.055751</td>\n",
              "      <td>-0.084870</td>\n",
              "      <td>-0.085159</td>\n",
              "      <td>-0.024352</td>\n",
              "      <td>-0.033951</td>\n",
              "      <td>-0.033951</td>\n",
              "      <td>-0.079348</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.034417</td>\n",
              "      <td>-0.050288</td>\n",
              "      <td>-0.050288</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.034417</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.034877</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.024352</td>\n",
              "      <td>-0.024352</td>\n",
              "      <td>-0.033951</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.024352</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.024352</td>\n",
              "      <td>-0.024352</td>\n",
              "      <td>-0.024352</td>\n",
              "      <td>-0.024352</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.024352</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.024352</td>\n",
              "      <td>-0.033951</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>0.946120</td>\n",
              "      <td>0.946120</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.946120</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.023720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>inflammatory_nails</th>\n",
              "      <td>-0.061573</td>\n",
              "      <td>0.331087</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.033480</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.067765</td>\n",
              "      <td>0.359845</td>\n",
              "      <td>-0.033480</td>\n",
              "      <td>-0.033480</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.122896</td>\n",
              "      <td>-0.033003</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.123844</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.033951</td>\n",
              "      <td>-0.049224</td>\n",
              "      <td>-0.033951</td>\n",
              "      <td>-0.049224</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.055419</td>\n",
              "      <td>-0.095290</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.048867</td>\n",
              "      <td>-0.061573</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.033480</td>\n",
              "      <td>-0.084290</td>\n",
              "      <td>-0.073467</td>\n",
              "      <td>-0.055751</td>\n",
              "      <td>-0.084870</td>\n",
              "      <td>-0.085159</td>\n",
              "      <td>-0.024352</td>\n",
              "      <td>-0.033951</td>\n",
              "      <td>-0.033951</td>\n",
              "      <td>-0.079348</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.034417</td>\n",
              "      <td>-0.050288</td>\n",
              "      <td>-0.050288</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.034417</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.034877</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.024352</td>\n",
              "      <td>-0.024352</td>\n",
              "      <td>-0.033951</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.024352</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.024352</td>\n",
              "      <td>-0.024352</td>\n",
              "      <td>-0.024352</td>\n",
              "      <td>-0.024352</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.024352</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.024352</td>\n",
              "      <td>-0.033951</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>0.946120</td>\n",
              "      <td>0.946120</td>\n",
              "      <td>0.946120</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.023720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>blister</th>\n",
              "      <td>-0.061573</td>\n",
              "      <td>0.331087</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.033480</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.067765</td>\n",
              "      <td>-0.061889</td>\n",
              "      <td>-0.033480</td>\n",
              "      <td>-0.033480</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.122896</td>\n",
              "      <td>-0.033003</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.123844</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.033951</td>\n",
              "      <td>-0.049224</td>\n",
              "      <td>-0.033951</td>\n",
              "      <td>-0.049224</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.055419</td>\n",
              "      <td>0.194578</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.048867</td>\n",
              "      <td>-0.061573</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.033480</td>\n",
              "      <td>-0.084290</td>\n",
              "      <td>-0.073467</td>\n",
              "      <td>-0.055751</td>\n",
              "      <td>-0.084870</td>\n",
              "      <td>-0.085159</td>\n",
              "      <td>-0.024352</td>\n",
              "      <td>-0.033951</td>\n",
              "      <td>-0.033951</td>\n",
              "      <td>-0.079348</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.034417</td>\n",
              "      <td>-0.050288</td>\n",
              "      <td>-0.050288</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.034417</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.034877</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.024352</td>\n",
              "      <td>-0.024352</td>\n",
              "      <td>-0.033951</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.024352</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.024352</td>\n",
              "      <td>-0.024352</td>\n",
              "      <td>-0.024352</td>\n",
              "      <td>-0.024352</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.024352</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.024352</td>\n",
              "      <td>-0.033951</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.946120</td>\n",
              "      <td>0.946120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>red_sore_around_nose</th>\n",
              "      <td>-0.061573</td>\n",
              "      <td>0.331087</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.033480</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.067765</td>\n",
              "      <td>-0.061889</td>\n",
              "      <td>-0.033480</td>\n",
              "      <td>-0.033480</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.122896</td>\n",
              "      <td>-0.033003</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.123844</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.033951</td>\n",
              "      <td>-0.049224</td>\n",
              "      <td>-0.033951</td>\n",
              "      <td>-0.049224</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.055419</td>\n",
              "      <td>0.194578</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.048867</td>\n",
              "      <td>-0.061573</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.033480</td>\n",
              "      <td>-0.084290</td>\n",
              "      <td>-0.073467</td>\n",
              "      <td>-0.055751</td>\n",
              "      <td>-0.084870</td>\n",
              "      <td>-0.085159</td>\n",
              "      <td>-0.024352</td>\n",
              "      <td>-0.033951</td>\n",
              "      <td>-0.033951</td>\n",
              "      <td>-0.079348</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.034417</td>\n",
              "      <td>-0.050288</td>\n",
              "      <td>-0.050288</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.034417</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.034877</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.024352</td>\n",
              "      <td>-0.024352</td>\n",
              "      <td>-0.033951</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.024352</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.024352</td>\n",
              "      <td>-0.024352</td>\n",
              "      <td>-0.024352</td>\n",
              "      <td>-0.024352</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.024352</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.024352</td>\n",
              "      <td>-0.033951</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>0.946120</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.946120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>yellow_crust_ooze</th>\n",
              "      <td>-0.061573</td>\n",
              "      <td>0.331087</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.033480</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.067765</td>\n",
              "      <td>-0.061889</td>\n",
              "      <td>-0.033480</td>\n",
              "      <td>-0.033480</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.122896</td>\n",
              "      <td>-0.033003</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.123844</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.033951</td>\n",
              "      <td>-0.049224</td>\n",
              "      <td>-0.033951</td>\n",
              "      <td>-0.049224</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.055419</td>\n",
              "      <td>0.194578</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.048867</td>\n",
              "      <td>-0.061573</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.033480</td>\n",
              "      <td>-0.084290</td>\n",
              "      <td>-0.073467</td>\n",
              "      <td>-0.055751</td>\n",
              "      <td>-0.084870</td>\n",
              "      <td>-0.085159</td>\n",
              "      <td>-0.024352</td>\n",
              "      <td>-0.033951</td>\n",
              "      <td>-0.033951</td>\n",
              "      <td>-0.079348</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.034417</td>\n",
              "      <td>-0.050288</td>\n",
              "      <td>-0.050288</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.034417</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.034877</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.024352</td>\n",
              "      <td>-0.024352</td>\n",
              "      <td>-0.033951</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.024352</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.024352</td>\n",
              "      <td>-0.024352</td>\n",
              "      <td>-0.024352</td>\n",
              "      <td>-0.024352</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.024352</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.024352</td>\n",
              "      <td>-0.033951</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.023073</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>-0.023720</td>\n",
              "      <td>0.946120</td>\n",
              "      <td>0.946120</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>132 rows × 132 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                       itching  ...  yellow_crust_ooze\n",
              "itching               1.000000  ...          -0.061573\n",
              "skin_rash             0.318158  ...           0.331087\n",
              "nodal_skin_eruptions  0.326439  ...          -0.023073\n",
              "continuous_sneezing  -0.086906  ...          -0.033480\n",
              "shivering            -0.059893  ...          -0.023073\n",
              "...                        ...  ...                ...\n",
              "small_dents_in_nails -0.061573  ...          -0.023720\n",
              "inflammatory_nails   -0.061573  ...          -0.023720\n",
              "blister              -0.061573  ...           0.946120\n",
              "red_sore_around_nose -0.061573  ...           0.946120\n",
              "yellow_crust_ooze    -0.061573  ...           1.000000\n",
              "\n",
              "[132 rows x 132 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWvswOkKzt84"
      },
      "source": [
        "##Plotting: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZZUJVGv23uW"
      },
      "source": [
        "##PREPROCESSING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBSCllCE4lqD"
      },
      "source": [
        "Scaling the values:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSJaVEiE26W9"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GC5IbBs13Kym"
      },
      "source": [
        "scale_cols = ['trestbps','chol','thalach', 'oldpeak']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZQ2Epf622UR"
      },
      "source": [
        "sc = StandardScaler()\n",
        "data[scale_cols] = sc.fit_transform(data[scale_cols])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4T0qI9z3xyy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "202913bb-6d31-4c35-d436-df6e93a74327"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0.763956</td>\n",
              "      <td>-0.256334</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.015443</td>\n",
              "      <td>0</td>\n",
              "      <td>1.087338</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.092738</td>\n",
              "      <td>0.072199</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.633471</td>\n",
              "      <td>0</td>\n",
              "      <td>2.122573</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.092738</td>\n",
              "      <td>-0.816773</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.977514</td>\n",
              "      <td>0</td>\n",
              "      <td>0.310912</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.663867</td>\n",
              "      <td>-0.198357</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.239897</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.206705</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.663867</td>\n",
              "      <td>2.082050</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.583939</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.379244</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age  sex  cp  trestbps      chol  ...   oldpeak  slope  ca  thal  target\n",
              "0    3    1   3  0.763956 -0.256334  ...  1.087338      0   0     1       1\n",
              "1    1    1   2 -0.092738  0.072199  ...  2.122573      0   0     2       1\n",
              "2    1    0   1 -0.092738 -0.816773  ...  0.310912      2   0     2       1\n",
              "3    3    1   1 -0.663867 -0.198357  ... -0.206705      2   0     2       1\n",
              "4    3    0   0 -0.663867  2.082050  ... -0.379244      2   0     2       1\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrI6P17r36C4"
      },
      "source": [
        "Checking if there are any NaN values\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vi2ueWiR33o7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "35732525-889d-4947-f3ae-33f894e30cc7"
      },
      "source": [
        "data.isnull().values.any()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j90ljcAl4pMZ"
      },
      "source": [
        "##Splitting the dataset for Training and Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGom3dTW4cbx"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuIYSwVC6gRC"
      },
      "source": [
        "#x = data.iloc[:,:-1].values\n",
        "x = data.drop(['chol','fbs','target'],axis=1)\n",
        "y = data['target'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obOG6drk6Gc4"
      },
      "source": [
        "train_x , test_x , train_y , test_y = train_test_split(x , y , random_state=5 , test_size = 0.18 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rb9ZgVH06yva",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b9cfd848-b4bc-4607-fbcc-a19138ad78d1"
      },
      "source": [
        "print(\"training dataset : \" , train_x.shape)\n",
        "print(\"testing dataset : \" , test_x.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training dataset :  (248, 11)\n",
            "testing dataset :  (55, 11)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vbh3_LG57JGn"
      },
      "source": [
        "##Machine Learning Classification Models : \n",
        "\n",
        "Classification is a type of supervised learning. It specifies the class to which data elements belong to and is best used when the output has finite and discrete values. It predicts a class for an input variable as well.\n",
        "\n",
        "There are 2 types of Classification: \n",
        "\n",
        "* Binary\n",
        "* Multi-Class\n",
        "\n",
        "In this dataset , we have to do Binary Classification.\n",
        "\n",
        "**Types of Classification Algorithms**\n",
        "\n",
        "1. Linear Models\n",
        "* Logistic Regression\n",
        "* Support Vector Machines\n",
        "2. Nonlinear models\n",
        "* K-nearest Neighbors (KNN)\n",
        "* Kernel Support Vector Machines (SVM)\n",
        "* Naïve Bayes\n",
        "* Decision Tree Classification\n",
        "* Random Forest Classification\n",
        "* XGBoost Classification\n",
        "\n",
        "We will be using all the classification methods on this dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Z549BVwGTj6"
      },
      "source": [
        "acc_model = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNLhN3ra8Xvy"
      },
      "source": [
        "Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9LaN9hC8M0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c7598e8d-fad1-4969-8242-393d4518fe51"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "lgr = LogisticRegression()\n",
        "pred = lgr.fit(train_x,train_y).predict(test_x)\n",
        "acc = accuracy_score(test_y,pred)\n",
        "acc_train = accuracy_score(lgr.predict(train_x),train_y)\n",
        "print(\"Accuracy on Train dataset: \" , acc_train)\n",
        "print(\"Accuracy on Test dataset: \" , acc)\n",
        "acc_model['Logistic Regression'] = acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on Train dataset:  0.8387096774193549\n",
            "Accuracy on Test dataset:  0.9272727272727272\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xQxQXd28v3O"
      },
      "source": [
        "Support Vector Machines(Linear)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2IuR3ko8uZO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "f5c9d446-5053-4e3e-c49a-c8d9f1105404"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "svm_lin = SVC(kernel = 'linear',C = 0.025,random_state=42)\n",
        "pred = svm_lin.fit(train_x,train_y).predict(test_x)\n",
        "acc = accuracy_score(test_y,pred)\n",
        "acc_train = accuracy_score(svm_lin.predict(train_x),train_y)\n",
        "print(\"Accuracy on Train dataset: \" , acc_train)\n",
        "print(\"Accuracy on Test dataset: \" , acc)\n",
        "acc_model['Support Vector Machines(Linear)'] = acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on Train dataset:  0.8306451612903226\n",
            "Accuracy on Test dataset:  0.9272727272727272\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bX-vPoDL9Mpc"
      },
      "source": [
        "K-nearest Neighbors (KNN)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubjZ2H-o9Ina"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "nearest_neighbor_score_test = {}\n",
        "for i in range(1,20):\n",
        "  knn = KNeighborsClassifier(n_neighbors = i,weights = 'uniform',algorithm = 'kd_tree',leaf_size = 30)\n",
        "  pred = knn.fit(train_x,train_y).predict(test_x)\n",
        "  nearest_neighbor_score_test[i] = accuracy_score(test_y,pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmGTwcKO-Njh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "25ceaa91-c145-4c64-910f-484ed1ed81f1"
      },
      "source": [
        "max_key_test = max(nearest_neighbor_score_test, key=nearest_neighbor_score_test.get)\n",
        "print(max_key_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CLZQpFwAklW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7b17564f-2395-4840-da91-9499895678d3"
      },
      "source": [
        "knn = KNeighborsClassifier(n_neighbors = max_key_test,algorithm='kd_tree',leaf_size = 30)\n",
        "pred = knn.fit(train_x,train_y).predict(test_x)\n",
        "acc = accuracy_score(test_y,pred)\n",
        "acc_train = accuracy_score(knn.predict(train_x),train_y)\n",
        "print(\"Accuracy on Train dataset: \" , acc_train)\n",
        "print(\"Accuracy on Test dataset: \" , acc)\n",
        "acc_model['K-nearest Neighbors (KNN)'] = acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on Train dataset:  0.8790322580645161\n",
            "Accuracy on Test dataset:  0.9454545454545454\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n10EvvPaRh7F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "1f7e83c6-b058-4c7b-a5a6-aeea0fd76f76"
      },
      "source": [
        "cm = confusion_matrix(test_y,pred)\n",
        "plt.figure(figsize=(4,3))\n",
        "sns.heatmap(cm, cmap=mycmap,annot=True)# font size\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[26  1]\n",
            " [ 2 26]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x216 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_fV6jhTNql2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "b078f6b1-a282-4993-a42d-13e485a297f9"
      },
      "source": [
        "print(classification_report(test_y,pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.96      0.95        27\n",
            "           1       0.96      0.93      0.95        28\n",
            "\n",
            "    accuracy                           0.95        55\n",
            "   macro avg       0.95      0.95      0.95        55\n",
            "weighted avg       0.95      0.95      0.95        55\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fs9hiY49BgUf"
      },
      "source": [
        "Kernel - RBF Support Vector Machines (SVM)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usMU8akBBH_g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "771f312c-9be0-4844-b821-47bc50c7606f"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "svm_rbf = SVC(kernel = 'rbf',random_state=42)\n",
        "pred = svm_rbf.fit(train_x,train_y).predict(test_x)\n",
        "acc = accuracy_score(test_y,pred)\n",
        "acc_train = accuracy_score(svm_rbf.predict(train_x),train_y)\n",
        "print(\"Accuracy on Train dataset: \" , acc_train)\n",
        "print(\"Accuracy on Test dataset: \" , acc)\n",
        "acc_model['Kernel - RBF Support Vector Machines (SVM)'] = acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on Train dataset:  0.875\n",
            "Accuracy on Test dataset:  0.9272727272727272\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZPn2xUtCpYp"
      },
      "source": [
        "Kernel - Sigmoid Support Vector Machines (SVM)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MiWpnonCGsj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "39f60a24-e60c-4a29-f3ca-26ae8e0f4dd1"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "svm_s = SVC(kernel = 'sigmoid',random_state=42)\n",
        "pred = svm_s.fit(train_x,train_y).predict(test_x)\n",
        "acc = accuracy_score(test_y,pred)\n",
        "acc_train = accuracy_score(svm_s.predict(train_x),train_y)\n",
        "print(\"Accuracy on Train dataset: \" , acc_train)\n",
        "print(\"Accuracy on Test dataset: \" , acc)\n",
        "acc_model['Kernel - Sigmoid Support Vector Machines (SVM)'] = acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on Train dataset:  0.7701612903225806\n",
            "Accuracy on Test dataset:  0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQ2W8OUPCxhK"
      },
      "source": [
        "Kernel - Poly Support Vector Machines (SVM)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5AwZ87BCUQo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "3e654011-b54e-4fa5-b29d-26ed4b49db96"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "svm_p= SVC(kernel = 'poly',C = 0.025,random_state=42)\n",
        "pred = svm_p.fit(train_x,train_y).predict(test_x)\n",
        "acc = accuracy_score(test_y,pred)\n",
        "acc_train = accuracy_score(svm_s.predict(train_x),train_y)\n",
        "print(\"Accuracy on Train dataset: \" , acc_train)\n",
        "print(\"Accuracy on Test dataset: \" , acc)\n",
        "acc_model['Kernel - Poly Support Vector Machines (SVM)'] = acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on Train dataset:  0.7701612903225806\n",
            "Accuracy on Test dataset:  0.9272727272727272\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdym26PoCT4N"
      },
      "source": [
        "Gaussian Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DAq9172DAH5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "abdece95-c723-4c5d-c369-e6ff2325a0d2"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "nb = GaussianNB()\n",
        "pred = nb.fit(train_x,train_y).predict(test_x)\n",
        "acc = accuracy_score(test_y,pred)\n",
        "acc_train = accuracy_score(nb.predict(train_x),train_y)\n",
        "print(\"Accuracy on Train dataset: \" , acc_train)\n",
        "print(\"Accuracy on Test dataset: \" , acc)\n",
        "acc_model['Naive Bayes'] = acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on Train dataset:  0.8306451612903226\n",
            "Accuracy on Test dataset:  0.8727272727272727\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0dYukBGDJWV"
      },
      "source": [
        "Decision Tree Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-tn-zK7DEkv"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "score = {}\n",
        "for i in range(1,12):\n",
        "  dtree = DecisionTreeClassifier(max_features= i)\n",
        "  pred = dtree.fit(train_x,train_y).predict(test_x)\n",
        "  score[i] = accuracy_score(test_y,pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVWXZ0OHFzD0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "45771c3e-3c1b-484a-fb4c-f42a4c0b94c9"
      },
      "source": [
        "max_key_test_dtree = max(score, key=score.get)\n",
        "print(max_key_test)\n",
        "keys = score.keys()\n",
        "values = score.values()\n",
        "plt.bar(keys, values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 11 artists>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7g8tsy7nFSK6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "40eb92ac-0fc4-4324-dbc0-0efd1e0f52f3"
      },
      "source": [
        "dtree = DecisionTreeClassifier(max_features= max_key_test_dtree)\n",
        "pred = dtree.fit(train_x,train_y).predict(test_x)\n",
        "acc = accuracy_score(test_y,pred)\n",
        "acc_train = accuracy_score(dtree.predict(train_x),train_y)\n",
        "print(\"Accuracy on Train dataset: \" , acc_train)\n",
        "print(\"Accuracy on Test dataset: \" , acc)\n",
        "acc_model['Decision Tree Classifier'] = acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on Train dataset:  1.0\n",
            "Accuracy on Test dataset:  0.8181818181818182\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3CJYPGADxgc"
      },
      "source": [
        "Random Forest Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5DgT8JMDgln",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "3e56b41a-0192-481e-ff2e-f19ccd8ca16c"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier(n_estimators = 100 , random_state=42)\n",
        "pred = rf.fit(train_x,train_y).predict(test_x)\n",
        "acc = accuracy_score(test_y,pred)\n",
        "acc_train = accuracy_score(rf.predict(train_x),train_y)\n",
        "print(\"Accuracy on Train dataset: \" , acc_train)\n",
        "print(\"Accuracy on Test dataset: \" , acc)\n",
        "acc_model['Random Forest Classifier'] = acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on Train dataset:  1.0\n",
            "Accuracy on Test dataset:  0.9272727272727272\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StQtNCXCEThX"
      },
      "source": [
        "XGBoost Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMhQIIGiEOec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "0aab87eb-e3b9-48a6-c3dd-b0586b712963"
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "model = XGBClassifier()\n",
        "pred = model.fit(train_x,train_y).predict(test_x)\n",
        "acc = accuracy_score(test_y,pred)\n",
        "acc_train = accuracy_score(model.predict(train_x),train_y)\n",
        "print(\"Accuracy on Train dataset: \" , acc_train)\n",
        "print(\"Accuracy on Test dataset: \" , acc)\n",
        "acc_model['XGBoost Classifier'] = acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on Train dataset:  0.9596774193548387\n",
            "Accuracy on Test dataset:  0.9272727272727272\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eCxyOovLJnD"
      },
      "source": [
        "##Artificial Neural Network Approach"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZSkVneCNYs7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "780b4c88-8071-49b6-e7b7-4efdeccc764b"
      },
      "source": [
        "#Initialising the ANN\n",
        "clr = Sequential()\n",
        "# Adding the input layer and the first hidden layer\n",
        "clr.add(Dense(13, kernel_initializer='uniform',activation='relu',input_shape=(11,)))\n",
        "#clr.add(LeakyReLU(alpha=.01))   # add an advanced activation\n",
        "          \n",
        "# Adding the hidden layers\n",
        "clr.add(Dense(10, kernel_initializer='uniform',activation='relu'))\n",
        "clr.add(Dense(5, kernel_initializer='uniform',activation='relu'))\n",
        "clr.add(Dense(3, kernel_initializer='uniform',activation='relu'))\n",
        "\n",
        "#Adding the output layer\n",
        "clr.add(Dense(1, kernel_initializer='uniform',activation='relu'))\n",
        "          \n",
        "#Compiling the ANN\n",
        "clr.compile(optimizer = 'adam' , loss = 'binary_crossentropy' ,metrics = ['accuracy'])\n",
        "clr.fit(train_x , train_y , batch_size =32, epochs = 150)\n",
        "          \n",
        "#Predicting the Test set results\n",
        "pred = clr.predict(test_x)  \n",
        "pred = pred>0.5\n",
        "acc = accuracy_score(test_y,pred) \n",
        "acc_train = accuracy_score(model.predict(train_x)>0.5,train_y)\n",
        "print(\"Accuracy on Train dataset: \" , acc_train)\n",
        "print(\"Accuracy on Test dataset: \" , acc)\n",
        "acc_model['Neural Networks'] = acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "248/248 [==============================] - 0s 568us/step - loss: 3.9222 - accuracy: 0.4476\n",
            "Epoch 2/150\n",
            "248/248 [==============================] - 0s 107us/step - loss: 3.0314 - accuracy: 0.4476\n",
            "Epoch 3/150\n",
            "248/248 [==============================] - 0s 111us/step - loss: 2.9177 - accuracy: 0.4476\n",
            "Epoch 4/150\n",
            "248/248 [==============================] - 0s 108us/step - loss: 2.8693 - accuracy: 0.4476\n",
            "Epoch 5/150\n",
            "248/248 [==============================] - 0s 110us/step - loss: 2.8452 - accuracy: 0.4476\n",
            "Epoch 6/150\n",
            "248/248 [==============================] - 0s 105us/step - loss: 2.8308 - accuracy: 0.4476\n",
            "Epoch 7/150\n",
            "248/248 [==============================] - 0s 107us/step - loss: 2.8204 - accuracy: 0.4476\n",
            "Epoch 8/150\n",
            "248/248 [==============================] - 0s 103us/step - loss: 2.8105 - accuracy: 0.4476\n",
            "Epoch 9/150\n",
            "248/248 [==============================] - 0s 110us/step - loss: 2.7985 - accuracy: 0.4476\n",
            "Epoch 10/150\n",
            "248/248 [==============================] - 0s 105us/step - loss: 2.7808 - accuracy: 0.4476\n",
            "Epoch 11/150\n",
            "248/248 [==============================] - 0s 113us/step - loss: 2.7516 - accuracy: 0.4476\n",
            "Epoch 12/150\n",
            "248/248 [==============================] - 0s 107us/step - loss: 2.7072 - accuracy: 0.4476\n",
            "Epoch 13/150\n",
            "248/248 [==============================] - 0s 111us/step - loss: 2.6330 - accuracy: 0.4476\n",
            "Epoch 14/150\n",
            "248/248 [==============================] - 0s 104us/step - loss: 2.5243 - accuracy: 0.4476\n",
            "Epoch 15/150\n",
            "248/248 [==============================] - 0s 124us/step - loss: 2.3692 - accuracy: 0.4476\n",
            "Epoch 16/150\n",
            "248/248 [==============================] - 0s 114us/step - loss: 2.1790 - accuracy: 0.4476\n",
            "Epoch 17/150\n",
            "248/248 [==============================] - 0s 121us/step - loss: 1.9777 - accuracy: 0.4476\n",
            "Epoch 18/150\n",
            "248/248 [==============================] - 0s 112us/step - loss: 1.7688 - accuracy: 0.4476\n",
            "Epoch 19/150\n",
            "248/248 [==============================] - 0s 106us/step - loss: 1.5749 - accuracy: 0.4476\n",
            "Epoch 20/150\n",
            "248/248 [==============================] - 0s 108us/step - loss: 1.4016 - accuracy: 0.4476\n",
            "Epoch 21/150\n",
            "248/248 [==============================] - 0s 106us/step - loss: 1.2468 - accuracy: 0.4476\n",
            "Epoch 22/150\n",
            "248/248 [==============================] - 0s 108us/step - loss: 1.1132 - accuracy: 0.4476\n",
            "Epoch 23/150\n",
            "248/248 [==============================] - 0s 132us/step - loss: 0.9989 - accuracy: 0.4476\n",
            "Epoch 24/150\n",
            "248/248 [==============================] - 0s 144us/step - loss: 0.9028 - accuracy: 0.4476\n",
            "Epoch 25/150\n",
            "248/248 [==============================] - 0s 127us/step - loss: 0.8277 - accuracy: 0.4476\n",
            "Epoch 26/150\n",
            "248/248 [==============================] - 0s 114us/step - loss: 0.7671 - accuracy: 0.4476\n",
            "Epoch 27/150\n",
            "248/248 [==============================] - 0s 117us/step - loss: 0.7203 - accuracy: 0.4879\n",
            "Epoch 28/150\n",
            "248/248 [==============================] - 0s 122us/step - loss: 0.6887 - accuracy: 0.5000\n",
            "Epoch 29/150\n",
            "248/248 [==============================] - 0s 156us/step - loss: 0.6655 - accuracy: 0.5927\n",
            "Epoch 30/150\n",
            "248/248 [==============================] - 0s 116us/step - loss: 0.6498 - accuracy: 0.6532\n",
            "Epoch 31/150\n",
            "248/248 [==============================] - 0s 117us/step - loss: 0.6382 - accuracy: 0.6653\n",
            "Epoch 32/150\n",
            "248/248 [==============================] - 0s 110us/step - loss: 0.6279 - accuracy: 0.6532\n",
            "Epoch 33/150\n",
            "248/248 [==============================] - 0s 110us/step - loss: 0.6190 - accuracy: 0.6613\n",
            "Epoch 34/150\n",
            "248/248 [==============================] - 0s 116us/step - loss: 0.6103 - accuracy: 0.6774\n",
            "Epoch 35/150\n",
            "248/248 [==============================] - 0s 112us/step - loss: 0.6021 - accuracy: 0.6855\n",
            "Epoch 36/150\n",
            "248/248 [==============================] - 0s 108us/step - loss: 0.5935 - accuracy: 0.6935\n",
            "Epoch 37/150\n",
            "248/248 [==============================] - 0s 113us/step - loss: 0.5856 - accuracy: 0.7016\n",
            "Epoch 38/150\n",
            "248/248 [==============================] - 0s 116us/step - loss: 0.5777 - accuracy: 0.7097\n",
            "Epoch 39/150\n",
            "248/248 [==============================] - 0s 106us/step - loss: 0.5701 - accuracy: 0.7137\n",
            "Epoch 40/150\n",
            "248/248 [==============================] - 0s 108us/step - loss: 0.5629 - accuracy: 0.7218\n",
            "Epoch 41/150\n",
            "248/248 [==============================] - 0s 109us/step - loss: 0.5561 - accuracy: 0.7218\n",
            "Epoch 42/150\n",
            "248/248 [==============================] - 0s 120us/step - loss: 0.5485 - accuracy: 0.7298\n",
            "Epoch 43/150\n",
            "248/248 [==============================] - 0s 113us/step - loss: 0.5425 - accuracy: 0.7298\n",
            "Epoch 44/150\n",
            "248/248 [==============================] - 0s 110us/step - loss: 0.5355 - accuracy: 0.7339\n",
            "Epoch 45/150\n",
            "248/248 [==============================] - 0s 111us/step - loss: 0.5302 - accuracy: 0.7298\n",
            "Epoch 46/150\n",
            "248/248 [==============================] - 0s 104us/step - loss: 0.5236 - accuracy: 0.7339\n",
            "Epoch 47/150\n",
            "248/248 [==============================] - 0s 114us/step - loss: 0.5202 - accuracy: 0.7419\n",
            "Epoch 48/150\n",
            "248/248 [==============================] - 0s 114us/step - loss: 0.5143 - accuracy: 0.7540\n",
            "Epoch 49/150\n",
            "248/248 [==============================] - 0s 105us/step - loss: 0.5099 - accuracy: 0.7460\n",
            "Epoch 50/150\n",
            "248/248 [==============================] - 0s 103us/step - loss: 0.5046 - accuracy: 0.7500\n",
            "Epoch 51/150\n",
            "248/248 [==============================] - 0s 105us/step - loss: 0.5000 - accuracy: 0.7581\n",
            "Epoch 52/150\n",
            "248/248 [==============================] - 0s 103us/step - loss: 0.4968 - accuracy: 0.7702\n",
            "Epoch 53/150\n",
            "248/248 [==============================] - 0s 104us/step - loss: 0.4937 - accuracy: 0.7621\n",
            "Epoch 54/150\n",
            "248/248 [==============================] - 0s 115us/step - loss: 0.4895 - accuracy: 0.7540\n",
            "Epoch 55/150\n",
            "248/248 [==============================] - 0s 152us/step - loss: 0.4857 - accuracy: 0.7581\n",
            "Epoch 56/150\n",
            "248/248 [==============================] - 0s 114us/step - loss: 0.4835 - accuracy: 0.7661\n",
            "Epoch 57/150\n",
            "248/248 [==============================] - 0s 116us/step - loss: 0.4811 - accuracy: 0.7702\n",
            "Epoch 58/150\n",
            "248/248 [==============================] - 0s 110us/step - loss: 0.4790 - accuracy: 0.7702\n",
            "Epoch 59/150\n",
            "248/248 [==============================] - 0s 106us/step - loss: 0.4756 - accuracy: 0.7661\n",
            "Epoch 60/150\n",
            "248/248 [==============================] - 0s 107us/step - loss: 0.4735 - accuracy: 0.7702\n",
            "Epoch 61/150\n",
            "248/248 [==============================] - 0s 102us/step - loss: 0.4723 - accuracy: 0.7621\n",
            "Epoch 62/150\n",
            "248/248 [==============================] - 0s 124us/step - loss: 0.4702 - accuracy: 0.7581\n",
            "Epoch 63/150\n",
            "248/248 [==============================] - 0s 106us/step - loss: 0.4688 - accuracy: 0.7702\n",
            "Epoch 64/150\n",
            "248/248 [==============================] - 0s 109us/step - loss: 0.4670 - accuracy: 0.7742\n",
            "Epoch 65/150\n",
            "248/248 [==============================] - 0s 104us/step - loss: 0.4657 - accuracy: 0.7742\n",
            "Epoch 66/150\n",
            "248/248 [==============================] - 0s 105us/step - loss: 0.4639 - accuracy: 0.7782\n",
            "Epoch 67/150\n",
            "248/248 [==============================] - 0s 107us/step - loss: 0.4623 - accuracy: 0.7702\n",
            "Epoch 68/150\n",
            "248/248 [==============================] - 0s 107us/step - loss: 0.4616 - accuracy: 0.7782\n",
            "Epoch 69/150\n",
            "248/248 [==============================] - 0s 113us/step - loss: 0.4605 - accuracy: 0.7661\n",
            "Epoch 70/150\n",
            "248/248 [==============================] - 0s 103us/step - loss: 0.4586 - accuracy: 0.7742\n",
            "Epoch 71/150\n",
            "248/248 [==============================] - 0s 108us/step - loss: 0.4578 - accuracy: 0.7823\n",
            "Epoch 72/150\n",
            "248/248 [==============================] - 0s 110us/step - loss: 0.4561 - accuracy: 0.7823\n",
            "Epoch 73/150\n",
            "248/248 [==============================] - 0s 104us/step - loss: 0.4559 - accuracy: 0.7823\n",
            "Epoch 74/150\n",
            "248/248 [==============================] - 0s 109us/step - loss: 0.4547 - accuracy: 0.7823\n",
            "Epoch 75/150\n",
            "248/248 [==============================] - 0s 106us/step - loss: 0.4538 - accuracy: 0.7782\n",
            "Epoch 76/150\n",
            "248/248 [==============================] - 0s 103us/step - loss: 0.4529 - accuracy: 0.7742\n",
            "Epoch 77/150\n",
            "248/248 [==============================] - 0s 105us/step - loss: 0.4516 - accuracy: 0.7823\n",
            "Epoch 78/150\n",
            "248/248 [==============================] - 0s 119us/step - loss: 0.4507 - accuracy: 0.7702\n",
            "Epoch 79/150\n",
            "248/248 [==============================] - 0s 105us/step - loss: 0.4505 - accuracy: 0.7742\n",
            "Epoch 80/150\n",
            "248/248 [==============================] - 0s 110us/step - loss: 0.4512 - accuracy: 0.7742\n",
            "Epoch 81/150\n",
            "248/248 [==============================] - 0s 118us/step - loss: 0.4477 - accuracy: 0.7782\n",
            "Epoch 82/150\n",
            "248/248 [==============================] - 0s 110us/step - loss: 0.4480 - accuracy: 0.7742\n",
            "Epoch 83/150\n",
            "248/248 [==============================] - 0s 115us/step - loss: 0.4472 - accuracy: 0.7782\n",
            "Epoch 84/150\n",
            "248/248 [==============================] - 0s 107us/step - loss: 0.4454 - accuracy: 0.7782\n",
            "Epoch 85/150\n",
            "248/248 [==============================] - 0s 109us/step - loss: 0.4451 - accuracy: 0.7782\n",
            "Epoch 86/150\n",
            "248/248 [==============================] - 0s 106us/step - loss: 0.4452 - accuracy: 0.7863\n",
            "Epoch 87/150\n",
            "248/248 [==============================] - 0s 108us/step - loss: 0.4449 - accuracy: 0.7782\n",
            "Epoch 88/150\n",
            "248/248 [==============================] - 0s 105us/step - loss: 0.4430 - accuracy: 0.7782\n",
            "Epoch 89/150\n",
            "248/248 [==============================] - 0s 124us/step - loss: 0.4420 - accuracy: 0.7823\n",
            "Epoch 90/150\n",
            "248/248 [==============================] - 0s 106us/step - loss: 0.4441 - accuracy: 0.7903\n",
            "Epoch 91/150\n",
            "248/248 [==============================] - 0s 114us/step - loss: 0.4394 - accuracy: 0.7863\n",
            "Epoch 92/150\n",
            "248/248 [==============================] - 0s 107us/step - loss: 0.4412 - accuracy: 0.7782\n",
            "Epoch 93/150\n",
            "248/248 [==============================] - 0s 108us/step - loss: 0.4396 - accuracy: 0.7782\n",
            "Epoch 94/150\n",
            "248/248 [==============================] - 0s 110us/step - loss: 0.4384 - accuracy: 0.7863\n",
            "Epoch 95/150\n",
            "248/248 [==============================] - 0s 105us/step - loss: 0.4400 - accuracy: 0.7903\n",
            "Epoch 96/150\n",
            "248/248 [==============================] - 0s 112us/step - loss: 0.4376 - accuracy: 0.7863\n",
            "Epoch 97/150\n",
            "248/248 [==============================] - 0s 133us/step - loss: 0.4366 - accuracy: 0.7863\n",
            "Epoch 98/150\n",
            "248/248 [==============================] - 0s 112us/step - loss: 0.4378 - accuracy: 0.7863\n",
            "Epoch 99/150\n",
            "248/248 [==============================] - 0s 110us/step - loss: 0.4368 - accuracy: 0.7903\n",
            "Epoch 100/150\n",
            "248/248 [==============================] - 0s 104us/step - loss: 0.4369 - accuracy: 0.7863\n",
            "Epoch 101/150\n",
            "248/248 [==============================] - 0s 108us/step - loss: 0.4358 - accuracy: 0.7863\n",
            "Epoch 102/150\n",
            "248/248 [==============================] - 0s 108us/step - loss: 0.4343 - accuracy: 0.7903\n",
            "Epoch 103/150\n",
            "248/248 [==============================] - 0s 110us/step - loss: 0.4346 - accuracy: 0.7903\n",
            "Epoch 104/150\n",
            "248/248 [==============================] - 0s 108us/step - loss: 0.4331 - accuracy: 0.7863\n",
            "Epoch 105/150\n",
            "248/248 [==============================] - 0s 111us/step - loss: 0.4309 - accuracy: 0.7903\n",
            "Epoch 106/150\n",
            "248/248 [==============================] - 0s 108us/step - loss: 0.4321 - accuracy: 0.7863\n",
            "Epoch 107/150\n",
            "248/248 [==============================] - 0s 121us/step - loss: 0.4304 - accuracy: 0.7903\n",
            "Epoch 108/150\n",
            "248/248 [==============================] - 0s 110us/step - loss: 0.4304 - accuracy: 0.7903\n",
            "Epoch 109/150\n",
            "248/248 [==============================] - 0s 123us/step - loss: 0.4290 - accuracy: 0.7903\n",
            "Epoch 110/150\n",
            "248/248 [==============================] - 0s 116us/step - loss: 0.4280 - accuracy: 0.7984\n",
            "Epoch 111/150\n",
            "248/248 [==============================] - 0s 110us/step - loss: 0.4282 - accuracy: 0.7984\n",
            "Epoch 112/150\n",
            "248/248 [==============================] - 0s 105us/step - loss: 0.4269 - accuracy: 0.8024\n",
            "Epoch 113/150\n",
            "248/248 [==============================] - 0s 101us/step - loss: 0.4256 - accuracy: 0.7984\n",
            "Epoch 114/150\n",
            "248/248 [==============================] - 0s 110us/step - loss: 0.4254 - accuracy: 0.7984\n",
            "Epoch 115/150\n",
            "248/248 [==============================] - 0s 109us/step - loss: 0.4239 - accuracy: 0.7984\n",
            "Epoch 116/150\n",
            "248/248 [==============================] - 0s 107us/step - loss: 0.4240 - accuracy: 0.8065\n",
            "Epoch 117/150\n",
            "248/248 [==============================] - 0s 106us/step - loss: 0.4215 - accuracy: 0.8105\n",
            "Epoch 118/150\n",
            "248/248 [==============================] - 0s 103us/step - loss: 0.4218 - accuracy: 0.8065\n",
            "Epoch 119/150\n",
            "248/248 [==============================] - 0s 103us/step - loss: 0.4215 - accuracy: 0.8105\n",
            "Epoch 120/150\n",
            "248/248 [==============================] - 0s 101us/step - loss: 0.4213 - accuracy: 0.8105\n",
            "Epoch 121/150\n",
            "248/248 [==============================] - 0s 104us/step - loss: 0.4193 - accuracy: 0.8065\n",
            "Epoch 122/150\n",
            "248/248 [==============================] - 0s 107us/step - loss: 0.4177 - accuracy: 0.8105\n",
            "Epoch 123/150\n",
            "248/248 [==============================] - 0s 122us/step - loss: 0.4171 - accuracy: 0.8105\n",
            "Epoch 124/150\n",
            "248/248 [==============================] - 0s 111us/step - loss: 0.4162 - accuracy: 0.8105\n",
            "Epoch 125/150\n",
            "248/248 [==============================] - 0s 104us/step - loss: 0.4154 - accuracy: 0.8105\n",
            "Epoch 126/150\n",
            "248/248 [==============================] - 0s 101us/step - loss: 0.4152 - accuracy: 0.8105\n",
            "Epoch 127/150\n",
            "248/248 [==============================] - 0s 114us/step - loss: 0.4137 - accuracy: 0.8105\n",
            "Epoch 128/150\n",
            "248/248 [==============================] - 0s 107us/step - loss: 0.4128 - accuracy: 0.8105\n",
            "Epoch 129/150\n",
            "248/248 [==============================] - 0s 101us/step - loss: 0.4111 - accuracy: 0.8105\n",
            "Epoch 130/150\n",
            "248/248 [==============================] - 0s 104us/step - loss: 0.4100 - accuracy: 0.8105\n",
            "Epoch 131/150\n",
            "248/248 [==============================] - 0s 142us/step - loss: 0.4090 - accuracy: 0.8105\n",
            "Epoch 132/150\n",
            "248/248 [==============================] - 0s 108us/step - loss: 0.4090 - accuracy: 0.8065\n",
            "Epoch 133/150\n",
            "248/248 [==============================] - 0s 134us/step - loss: 0.4091 - accuracy: 0.8105\n",
            "Epoch 134/150\n",
            "248/248 [==============================] - 0s 115us/step - loss: 0.4065 - accuracy: 0.8105\n",
            "Epoch 135/150\n",
            "248/248 [==============================] - 0s 111us/step - loss: 0.4042 - accuracy: 0.8065\n",
            "Epoch 136/150\n",
            "248/248 [==============================] - 0s 103us/step - loss: 0.4048 - accuracy: 0.8105\n",
            "Epoch 137/150\n",
            "248/248 [==============================] - 0s 106us/step - loss: 0.4029 - accuracy: 0.8105\n",
            "Epoch 138/150\n",
            "248/248 [==============================] - 0s 106us/step - loss: 0.4023 - accuracy: 0.8105\n",
            "Epoch 139/150\n",
            "248/248 [==============================] - 0s 107us/step - loss: 0.4009 - accuracy: 0.8105\n",
            "Epoch 140/150\n",
            "248/248 [==============================] - 0s 109us/step - loss: 0.4002 - accuracy: 0.8105\n",
            "Epoch 141/150\n",
            "248/248 [==============================] - 0s 112us/step - loss: 0.3987 - accuracy: 0.8105\n",
            "Epoch 142/150\n",
            "248/248 [==============================] - 0s 106us/step - loss: 0.3986 - accuracy: 0.8105\n",
            "Epoch 143/150\n",
            "248/248 [==============================] - 0s 119us/step - loss: 0.3970 - accuracy: 0.8105\n",
            "Epoch 144/150\n",
            "248/248 [==============================] - 0s 104us/step - loss: 0.3957 - accuracy: 0.8105\n",
            "Epoch 145/150\n",
            "248/248 [==============================] - 0s 110us/step - loss: 0.3949 - accuracy: 0.8105\n",
            "Epoch 146/150\n",
            "248/248 [==============================] - 0s 102us/step - loss: 0.3938 - accuracy: 0.8145\n",
            "Epoch 147/150\n",
            "248/248 [==============================] - 0s 102us/step - loss: 0.3927 - accuracy: 0.8145\n",
            "Epoch 148/150\n",
            "248/248 [==============================] - 0s 114us/step - loss: 0.3933 - accuracy: 0.8145\n",
            "Epoch 149/150\n",
            "248/248 [==============================] - 0s 104us/step - loss: 0.3904 - accuracy: 0.8185\n",
            "Epoch 150/150\n",
            "248/248 [==============================] - 0s 106us/step - loss: 0.3922 - accuracy: 0.8145\n",
            "Accuracy on Train dataset:  0.9596774193548387\n",
            "Accuracy on Test dataset:  0.8727272727272727\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vw41xSRQOfOu"
      },
      "source": [
        "##Comparing the models :\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhdQbb3jOphr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "outputId": "deea8326-93db-4d2e-f08b-6bce2e9e726f"
      },
      "source": [
        "keys = acc_model.keys()\n",
        "values = acc_model.values()\n",
        "colors = rainbow(np.linspace(0, 1, len(acc_model)))\n",
        "plt.bar(keys, values,color = colors)\n",
        "plt.xticks(rotation = 90)\n",
        "max_acc= max(acc_model, key=acc_model.get)\n",
        "print(\"The Best accuracy is of the model {} : {}\" .format(max_acc,acc_model[max_acc]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Best accuracy is of the model K-nearest Neighbors (KNN) : 0.9454545454545454\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtOvEraVOWeo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "b5589b6c-1cde-4833-c876-78d694aa2b31"
      },
      "source": [
        "print(acc_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Logistic Regression': 0.9272727272727272, 'Support Vector Machines(Linear)': 0.9272727272727272, 'K-nearest Neighbors (KNN)': 0.9454545454545454, 'Kernel - RBF Support Vector Machines (SVM)': 0.9272727272727272, 'Kernel - Sigmoid Support Vector Machines (SVM)': 0.8, 'Kernel - Poly Support Vector Machines (SVM)': 0.9272727272727272, 'Naive Bayes': 0.8727272727272727, 'Decision Tree Classifier': 0.8181818181818182, 'Random Forest Classifier': 0.9272727272727272, 'XGBoost Classifier': 0.9272727272727272, 'Neural Networks': 0.8727272727272727}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIjgCZwYmGQS"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}